{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ca0207184084e8e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem Statment\n",
    "\n",
    "You have been provided a dataset that consists of echo-location clicks of two types of whales, namely, Gervais and Cuviers. In this assignment, your task is to classify the different types whales using Gradient Boosting with the help of the XGBoost library. You are expected to fill in functions that would complete this task. We use XGBoost here instead of GradientBoostedTrees in Spark because XGBoost running on a single machine is much faster than Spark running on 10 machines.\n",
    "\n",
    "The data files were preprocessed on PySpark (10 nodes) cluster. The code for the same can be found in Data_Processing_Whales.ipynb. The preprocessed data is a numpy array with `4175` rows (for the 10mb file) with following columns (zero-indexed):\n",
    "* Col 0-9: projections on first 10 eigen vectors\n",
    "* Col 10: rmse\n",
    "* Col 11: peak2peak\n",
    "* Col 12: label (`0 if row.species==u'Gervais' else 1`)\n",
    "\n",
    "You can also refer to XGBoost_Whales.ipynb under for more details on the XGBoost Analysis before you attempt this assignment.\n",
    "\n",
    "Both Data_Processing_Whales.ipynb and XGBoost_Whales.ipynb can be found under XGBoost directory that was uploaded in edX as a part of \"Notebooks for weeks 7 & 8\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9a38095cb19c5da",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## XGBoost - Theory\n",
    "\n",
    "A brief overview of gradient boosting in XGBoost can be found here:\n",
    "\n",
    "* http://xgboost.readthedocs.io/en/latest/model.html\n",
    "* http://xgboost.readthedocs.io/en/latest/python/python_intro.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-16f2db0bba8e52b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Use the XGBoost API for training and predicting scores: \n",
    "\n",
    "* http://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
    "\n",
    "#### Main API\n",
    "\n",
    "* `xgboost.train` is the learning API that trains the Gradient Boosting Model,\n",
    "   * The main parameters are:\n",
    "      * **plst** – XGBoost parameter list\n",
    "      * **dtrain** – Data to be trained\n",
    "      * **num_round** – Number of iterations of boosting. (default: 100)\n",
    "      * **evallist** – List of items to be evaluated during training\n",
    "      * **verbose_eval** - This can be used to control how much information the train function prints. You might want to set to **False** to avoid printing logs.\n",
    "* `bst.predict` is the API that makes score predictions\n",
    "   * The main parameters are:\n",
    "      * **dtest** – Test Data\n",
    "      * **dtrain** – Data to be trained\n",
    "      * **ntree_limit** – Limit number of trees in the prediction (Use: ntree_limit=bst.best_ntree_limit)\n",
    "      * **output_margin** - Whether to output the raw untransformed margin value (Use: output_margin=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f8a9b8bf526d4967",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cea38fbf19a333c3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2051a8eb18d3841d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49af45e27e1fbcc9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e6873f313a58bd8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with open('Data/X_train.pkl', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open('Data/X_test.pkl', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open('Data/y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open('Data/y_test.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b890b75f903371f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Setting Parameters for XG Boost\n",
    "* Maximum Depth of the Tree = 3 _(maximum depth of each decision trees)_\n",
    "* Step size shrinkage used in update to prevents overfitting = 0.3 _(how to weigh trees in subsequent iterations)_\n",
    "* Evaluation Criterion= Maximize Loglikelihood according to the logistic regression _(logitboost)_\n",
    "* Maximum Number of Iterations = 1000 _(total number trees for boosting)_\n",
    "* Early Stop if score on Validation does not improve for 5 iterations\n",
    "\n",
    "[Full description of options](https://xgboost.readthedocs.io/en/latest//parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#You can change this cell if you wish to, but you aren't expected to\n",
    "def xgboost_plst():\n",
    "    param = {}\n",
    "    param['max_depth']= 3   # depth of tree\n",
    "    param['eta'] = 0.3      # shrinkage parameter\n",
    "    param['silent'] = 1     # not silent\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param['nthread'] = 7 # Number of threads used\n",
    "    param['eval_metric'] = 'logloss'\n",
    "\n",
    "    plst = param.items()\n",
    "    return plst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fd45dc089bb662b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f3a7d30fcd07e202",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Computing the score ranges\n",
    "\n",
    "The function <font color=\"blue\">calc_stats</font> takes the xgboost margin scores as input and returns two numpy arrays min_scr, max_scr which are calculated as follows:\n",
    "\n",
    "1. **min_scr**: mean - (3 $\\times$ std)\n",
    "2. **max_scr**: mean + (3 $\\times$ std)\n",
    "\n",
    "Here the input margin scores, represents the processed XGBoost margin scores obtained from the <font color=\"blue\">bootstrap_pred</font> function. Each row represents the various scores for a specific example in an iteration and your <font color=\"blue\">calc_stats</font> function is supposed to compute the **min_scr** and **max_scr** as defined for each example. So in the example below, we take a scenario where we have 3 examples which have 4 values each (From 4 bootstrap iterations).\n",
    "\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Input</font>**\n",
    "``` python\n",
    "[[-0.22 -0.19 -0.17 -0.13][-0.1 -0.05 0.02 0.10][0.03 0.11 0.12 0.15]]\n",
    "```\n",
    "\n",
    "Output: min_scr (numpy array), max_scr (numpy array)\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "(array([-0.28 -0.23 -0.03]),\n",
    " array([-0.08  0.22  0.24]))\n",
    "```\n",
    "\n",
    "**Note**: Ensure you round the values in the numpy arrays to two decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61aa63fe2f976d34",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_stats(margin_scores):\n",
    "    \n",
    "    min_score, max_score = [], []\n",
    "    for score in margin_scores:\n",
    "        min_score.append(round(np.mean(score) - 3 * np.std(score), 2))\n",
    "        max_score.append(round(np.mean(score) + 3 * np.std(score), 2))\n",
    "    return np.array(min_score), np.array(max_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "calc_stats_rt",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "margin_score = np.array([[-0.22, -0.19, -0.17, -0.13], [-0.1, -0.05, 0.02, 0.10], [0.03, 0.11, 0.12, 0.15]])\n",
    "min_score, max_score = calc_stats(margin_score)\n",
    "assert type(min_score) == np.ndarray, 'Incorrect Return type'\n",
    "assert type(max_score) == np.ndarray, 'Incorrect Return type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "calc_stats_v1",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert (min_score == np.array([-0.28, -0.23, -0.03])).all(), \"Incorrect return value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "calc_stats_v2",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert (max_score == np.array([-0.08,  0.22,  0.24])).all(), \"Incorrect return value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "calc_stats_h1",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "calc_stats_h2",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c7302c453524b003",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Calculating predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0fda183618b920ae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Based on the ranges for each of the examples, i.e, (min_scr, max_scr), we can predict whether it's a Gervais or a Cuvier. Since all our scores will be between -1 and +1, we use 0 as the margin line. All examples which are on the left side of the margin, can be classified as Cuvier's and all which are on the right side can be classified as Gervais. However, since we take margin scores from a set of bootstraps for each example, we use the minimum and maximum score arrays to predict to determine the classification.\n",
    "\n",
    "The function <font color=\"blue\">predict</font> takes the minimum score array and maximum score array and returns predictions as follows:\n",
    "\n",
    "1. If respective minimum score and maximum score values are less than 0, predict -1 (**Cuvier's**)\n",
    "2. If respective minimum score value is less than 0 and maximum score value is greater than 0, predict 0 (**Unsure**)\n",
    "3. If respective minimum score and maximum score values are greater than 0, predict 1 (**Gervais**)\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Input</font>**\n",
    "``` python\n",
    "min_scr (numpy array) = [-0.78 -0.68 -0.6 -0.53 -0.47 -0.42 -0.32 -0.21 -0.07 0.22]\n",
    "\n",
    "max_scr (numpy array) = [-0.49 -0.39 -0.33 -0.25 -0.2 -0.11 -0.04 0.1 0.3 0.51]\n",
    "```\n",
    "Output: pred (numpy array of predictions)\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "[-1 -1 -1 -1 -1 -1 -1  0  0  1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca97c577ab4f263b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(min_scr, max_scr):\n",
    "    predict_list = []\n",
    "\n",
    "    for i in range(len(min_s)):\n",
    "        if min_s[i] < 0 and max_s[i] < 0:\n",
    "            predict_list.append(-1)\n",
    "        elif min_s[i] > 0 and max_s[i] > 0:\n",
    "            predict_list.append(1)\n",
    "        else:\n",
    "            predict_list.append(0)\n",
    "            \n",
    "    return np.array(predict_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d301b14f59c07d94",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "max_s = np.array([-0.49, -0.39, -0.33, -0.25, -0.2, -0.11, -0.04, 0.1, 0.3, 0.51])\n",
    "min_s = np.array([-0.78, -0.68, -0.6, -0.53, -0.47, -0.42, -0.32, -0.21, -0.07, 0.22])\n",
    "pred = predict(min_s, max_s)\n",
    "true_pred = np.array([-1, -1, -1, -1, -1, -1, -1, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "predictions_rt",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(pred) == np.ndarray, 'Incorrect return type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "predictions_v1",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert (pred == true_pred).all(), 'Incorrect return value'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41a6a742b1f707ef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Calculating scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-77e258b2e5469fe8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The function <font color=\"blue\">bootstrap_pred</font> takes as input:\n",
    "\n",
    "1. **Training set**\n",
    "1. **Test set**\n",
    "1. **n_bootstrap** Number of bootstrap samples that run XGBoost and trains one part of the sample set.\n",
    "1. **minR, maxR** two numbers such that $0 < minR < maxR < 1$ that define the fractions of the `n_bootstrap` scores that define the range.\n",
    "1. **bootstrap_size** - Number of bootstrap samples on which you will run XGBoost.\n",
    "1. **num_round** - Number of iterations for running xgboost\n",
    "1. **plst** - Parameter List\n",
    "\n",
    "The output should be a confidence interval for each example in the test set. Together with a prediction that is `Gervais / Cuviers / Unsure`. The prediction `unsure` is to be output if the confidence interval contains the point 0.\n",
    "After generating the confidence intervals, the function <font color=\"blue\">predict</font> can be used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58b87b301cf007",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Procedure**\n",
    "\n",
    "Repeat the given procedure for n_bootstrap number of iterations:\n",
    "\n",
    "For **n_bootstrap** iterations:\n",
    "* Sample **boostrap_size** indices from the training set **with replacmennt**\n",
    "* Create train and test data matrices (dtrain, dtest) using xgb.DMatrix(X_sample, label=y_sample)\n",
    "* Initialise the evallist parameter [(dtrain, 'train'), (dtest, 'eval')]\n",
    "* Train the model using the XGBoost train API and make score predictions using bst.predict object returned by XGB train API. Ensure you set **output_margin=True** to get raw untransformed output scores.\n",
    "* Normalize them by dividing them with the normalizing factor as max(scores) - min(scores) and round these values to a precision of two decimal places\n",
    "\n",
    "Then: \n",
    "* For each individual example, remove scores below the minRth percentile and greater than maxRth percentile (sort for each example if necessary)\n",
    "* Call the calc_stats function to compute min_scr and max_scr with the filtered margin scores as parameter\n",
    "* Return the min_scr and max_scr computed by the **calc_stat** function using the margin scores.\n",
    "      \n",
    "**Note**: You can experiment by changing **n_bootstraps**, but it takes about 200 iterations to get consistent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1140639583a712cb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_pred(X_train, X_test, y_train, y_test, n_bootstrap, minR, maxR, bootstrap_size, \\\n",
    "                   num_round=100, plst=xgboost_plst()):\n",
    "\n",
    "    dtest = xgb.DMatrix(X_test,label=y_test)\n",
    "    margin_scores = []\n",
    "    n_bootstrap = 100\n",
    "    n_samples = X_train.shape[0]\n",
    "    lbound,hbound = int(n_bootstrap*minR),int(n_bootstrap*maxR)\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        # Sample boostrap_size indices from the training set with replacement\n",
    "        random_idx = np.random.randint(0,n_samples,bootstrap_size)\n",
    "\n",
    "        # Create train and test data matrices (dtrain, dtest) using xgb.DMatrix(X_sample, label=y_sample)\n",
    "        X_sample,y_sample = X_train[random_idx],y_train[random_idx]\n",
    "        dtrain = xgb.DMatrix(X_sample,label=y_sample)\n",
    "\n",
    "        # Initialise the evallist parameter [(dtrain, 'train'), (dtest, 'eval')]\n",
    "        evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "        # Train the model using the XGBoost train API and make score predictions \n",
    "        model = xgb.train(params=plst,dtrain=dtrain,num_boost_round=num_round,evals=evallist,verbose_eval=False)\n",
    "        pred = model.predict(dtest, ntree_limit=model.best_ntree_limit, output_margin=True)\n",
    "\n",
    "        # Normalize them by dividing them with the normalizing factor as \n",
    "        # max(scores) - min(scores) and round these values to a precision of two decimal places\n",
    "        scores = (pred/(max(pred)-min(pred))).round(2)\n",
    "\n",
    "        margin_scores.append(np.sort(scores))\n",
    "    \n",
    "    margin_scores = np.array(margin_scores).T\n",
    "    \n",
    "    margin_scores = np.sort(margin_scores, axis=1)\n",
    "    \n",
    "    # For each individual example, remove scores below the minRth percentile \n",
    "    # and greater than maxRth percentile (sort for each example if necessary)\n",
    "    margin_scores = margin_scores[:,lbound:hbound]\n",
    "    \n",
    "    # Call the calc_stats function to compute min_scr and max_scr \n",
    "    # with the filtered margin scores as parameter\n",
    "    min_scr, max_scr = calc_stats(margin_scores)\n",
    "\n",
    "    return min_scr, max_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4b625830945c42ee",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def process(X_train, X_test, y_train, y_test, n_bootstrap=100):\n",
    "    min_scr, max_scr = bootstrap_pred(X_train, X_test, y_train, y_test, n_bootstrap=n_bootstrap, \\\n",
    "                                            minR=0.1, maxR=0.9, bootstrap_size=len(X_train))\n",
    "    pred = predict(min_scr, max_scr)\n",
    "    return min_scr, max_scr, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests\n",
    "\n",
    "How we test the function:\n",
    "1. We have computed the average mid-point of the range of values and verify that this midpoint is present in the range computed by your function\n",
    "2. We check that the length of the interval(max_scr-min_scr) is not more than twice the average length of the interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8a3c583c7115caaf",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.64 -0.62 -0.61 -0.6  -0.6  -0.6  -0.59 -0.59 -0.59 -0.59 -0.58 -0.58\n",
      "  -0.58 -0.58 -0.58 -0.58 -0.57 -0.57 -0.57 -0.57 -0.57 -0.57 -0.57 -0.57\n",
      "  -0.57 -0.56 -0.56 -0.56 -0.56 -0.56 -0.56 -0.56 -0.56 -0.55 -0.55 -0.55\n",
      "  -0.55 -0.55 -0.55 -0.55 -0.55 -0.55 -0.54 -0.54 -0.54 -0.54 -0.54 -0.54\n",
      "  -0.54 -0.54 -0.54 -0.53 -0.53 -0.53 -0.53 -0.53 -0.53 -0.53 -0.53 -0.53\n",
      "  -0.52 -0.52 -0.52 -0.52 -0.52 -0.52 -0.52 -0.52 -0.52 -0.52 -0.52 -0.51\n",
      "  -0.51 -0.51 -0.51 -0.51 -0.5  -0.5  -0.5  -0.5  -0.5  -0.5  -0.5  -0.49\n",
      "  -0.49 -0.49 -0.49 -0.48 -0.48 -0.47 -0.47 -0.47 -0.47 -0.47 -0.47 -0.46\n",
      "  -0.46 -0.44 -0.42 -0.4 ]\n",
      " [-0.56 -0.55 -0.55 -0.54 -0.52 -0.51 -0.51 -0.5  -0.5  -0.49 -0.49 -0.49\n",
      "  -0.49 -0.48 -0.47 -0.47 -0.47 -0.47 -0.46 -0.46 -0.46 -0.45 -0.45 -0.45\n",
      "  -0.45 -0.45 -0.44 -0.44 -0.43 -0.43 -0.43 -0.42 -0.41 -0.41 -0.4  -0.4\n",
      "  -0.4  -0.4  -0.4  -0.39 -0.38 -0.38 -0.38 -0.38 -0.38 -0.37 -0.37 -0.37\n",
      "  -0.37 -0.37 -0.37 -0.36 -0.36 -0.36 -0.35 -0.35 -0.35 -0.35 -0.35 -0.35\n",
      "  -0.34 -0.34 -0.34 -0.34 -0.34 -0.34 -0.33 -0.33 -0.32 -0.32 -0.32 -0.32\n",
      "  -0.32 -0.32 -0.32 -0.32 -0.32 -0.32 -0.31 -0.31 -0.3  -0.3  -0.29 -0.29\n",
      "  -0.29 -0.29 -0.28 -0.28 -0.28 -0.28 -0.27 -0.26 -0.26 -0.25 -0.25 -0.24\n",
      "  -0.23 -0.23 -0.21 -0.2 ]\n",
      " [-0.54 -0.53 -0.52 -0.51 -0.5  -0.5  -0.5  -0.49 -0.49 -0.49 -0.49 -0.47\n",
      "  -0.46 -0.46 -0.46 -0.45 -0.45 -0.45 -0.45 -0.45 -0.44 -0.44 -0.44 -0.43\n",
      "  -0.43 -0.42 -0.42 -0.41 -0.41 -0.4  -0.4  -0.4  -0.4  -0.4  -0.4  -0.39\n",
      "  -0.38 -0.38 -0.38 -0.37 -0.37 -0.37 -0.37 -0.37 -0.37 -0.37 -0.36 -0.35\n",
      "  -0.35 -0.35 -0.35 -0.35 -0.35 -0.34 -0.34 -0.34 -0.34 -0.34 -0.33 -0.33\n",
      "  -0.33 -0.32 -0.32 -0.32 -0.32 -0.32 -0.32 -0.32 -0.32 -0.31 -0.31 -0.31\n",
      "  -0.31 -0.3  -0.3  -0.3  -0.29 -0.29 -0.28 -0.28 -0.28 -0.28 -0.28 -0.27\n",
      "  -0.27 -0.26 -0.26 -0.26 -0.26 -0.25 -0.25 -0.25 -0.24 -0.23 -0.23 -0.21\n",
      "  -0.21 -0.21 -0.21 -0.2 ]\n",
      " [-0.48 -0.42 -0.42 -0.42 -0.41 -0.4  -0.39 -0.39 -0.39 -0.38 -0.37 -0.36\n",
      "  -0.36 -0.36 -0.36 -0.36 -0.35 -0.34 -0.34 -0.34 -0.34 -0.33 -0.32 -0.32\n",
      "  -0.32 -0.31 -0.31 -0.31 -0.31 -0.31 -0.3  -0.3  -0.3  -0.3  -0.3  -0.29\n",
      "  -0.29 -0.29 -0.29 -0.29 -0.28 -0.28 -0.28 -0.28 -0.28 -0.28 -0.28 -0.27\n",
      "  -0.27 -0.27 -0.27 -0.26 -0.26 -0.26 -0.26 -0.26 -0.26 -0.26 -0.26 -0.26\n",
      "  -0.26 -0.25 -0.25 -0.25 -0.25 -0.25 -0.24 -0.24 -0.24 -0.23 -0.23 -0.23\n",
      "  -0.23 -0.22 -0.22 -0.22 -0.22 -0.22 -0.22 -0.21 -0.21 -0.21 -0.21 -0.21\n",
      "  -0.21 -0.2  -0.2  -0.2  -0.2  -0.19 -0.19 -0.18 -0.17 -0.16 -0.15 -0.14\n",
      "  -0.13 -0.1  -0.09 -0.08]\n",
      " [-0.23 -0.23 -0.23 -0.22 -0.19 -0.19 -0.18 -0.17 -0.17 -0.16 -0.15 -0.14\n",
      "  -0.14 -0.13 -0.13 -0.13 -0.13 -0.12 -0.12 -0.11 -0.11 -0.11 -0.11 -0.11\n",
      "  -0.1  -0.1  -0.1  -0.1  -0.1  -0.09 -0.09 -0.09 -0.09 -0.09 -0.08 -0.08\n",
      "  -0.08 -0.08 -0.08 -0.07 -0.07 -0.07 -0.07 -0.07 -0.07 -0.07 -0.06 -0.06\n",
      "  -0.06 -0.06 -0.06 -0.06 -0.05 -0.05 -0.05 -0.05 -0.04 -0.04 -0.04 -0.04\n",
      "  -0.04 -0.04 -0.04 -0.04 -0.03 -0.03 -0.03 -0.03 -0.03 -0.03 -0.03 -0.03\n",
      "  -0.03 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 -0.01 -0.01 -0.01 -0.01  0.\n",
      "   0.    0.   -0.    0.    0.01  0.01  0.01  0.01  0.01  0.03  0.04  0.04\n",
      "   0.04  0.05  0.07  0.1 ]\n",
      " [-0.12 -0.1  -0.1  -0.09 -0.08 -0.07 -0.06 -0.06 -0.05 -0.05 -0.05 -0.05\n",
      "  -0.05 -0.05 -0.05 -0.04 -0.04 -0.04 -0.04 -0.04 -0.03 -0.03 -0.03 -0.03\n",
      "  -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.01 -0.01 -0.01 -0.01 -0.01\n",
      "  -0.01 -0.01 -0.01  0.    0.    0.    0.   -0.   -0.    0.01  0.01  0.01\n",
      "   0.01  0.01  0.01  0.01  0.01  0.01  0.02  0.02  0.02  0.02  0.02  0.02\n",
      "   0.02  0.02  0.02  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.04  0.04\n",
      "   0.04  0.04  0.04  0.05  0.05  0.05  0.05  0.05  0.05  0.06  0.06  0.06\n",
      "   0.07  0.07  0.07  0.07  0.07  0.08  0.08  0.09  0.09  0.09  0.1   0.12\n",
      "   0.12  0.12  0.13  0.14]\n",
      " [-0.04 -0.03 -0.03 -0.02 -0.01 -0.01 -0.01 -0.    0.    0.01  0.02  0.02\n",
      "   0.02  0.03  0.03  0.03  0.03  0.03  0.03  0.04  0.04  0.04  0.04  0.04\n",
      "   0.04  0.04  0.05  0.05  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.07\n",
      "   0.07  0.07  0.07  0.08  0.08  0.08  0.08  0.08  0.08  0.08  0.08  0.09\n",
      "   0.09  0.09  0.09  0.09  0.09  0.1   0.1   0.1   0.1   0.1   0.11  0.11\n",
      "   0.11  0.11  0.11  0.11  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13\n",
      "   0.13  0.13  0.13  0.13  0.14  0.14  0.14  0.14  0.15  0.15  0.15  0.16\n",
      "   0.17  0.17  0.17  0.17  0.17  0.18  0.18  0.18  0.18  0.19  0.19  0.19\n",
      "   0.2   0.2   0.23  0.23]\n",
      " [ 0.08  0.09  0.1   0.1   0.11  0.11  0.12  0.12  0.12  0.13  0.13  0.13\n",
      "   0.13  0.13  0.13  0.14  0.14  0.14  0.14  0.14  0.14  0.15  0.16  0.16\n",
      "   0.16  0.16  0.16  0.17  0.17  0.17  0.17  0.17  0.17  0.17  0.18  0.18\n",
      "   0.18  0.18  0.19  0.19  0.19  0.19  0.19  0.19  0.19  0.19  0.19  0.2\n",
      "   0.2   0.2   0.2   0.2   0.2   0.2   0.21  0.21  0.21  0.21  0.21  0.21\n",
      "   0.21  0.22  0.22  0.22  0.22  0.22  0.22  0.22  0.23  0.23  0.23  0.23\n",
      "   0.23  0.23  0.24  0.24  0.24  0.24  0.24  0.24  0.25  0.25  0.25  0.25\n",
      "   0.25  0.25  0.25  0.25  0.25  0.25  0.26  0.27  0.27  0.27  0.27  0.28\n",
      "   0.29  0.29  0.31  0.35]\n",
      " [ 0.18  0.21  0.23  0.25  0.26  0.26  0.27  0.27  0.27  0.27  0.28  0.28\n",
      "   0.29  0.29  0.29  0.29  0.3   0.3   0.3   0.3   0.31  0.31  0.31  0.31\n",
      "   0.32  0.32  0.32  0.32  0.32  0.33  0.33  0.33  0.33  0.33  0.34  0.34\n",
      "   0.34  0.34  0.34  0.34  0.34  0.35  0.35  0.36  0.36  0.36  0.36  0.37\n",
      "   0.37  0.37  0.38  0.38  0.39  0.39  0.39  0.39  0.39  0.39  0.39  0.4\n",
      "   0.4   0.4   0.4   0.4   0.4   0.4   0.4   0.4   0.41  0.41  0.41  0.41\n",
      "   0.41  0.41  0.41  0.41  0.41  0.41  0.42  0.42  0.42  0.42  0.43  0.44\n",
      "   0.44  0.44  0.44  0.44  0.44  0.45  0.46  0.46  0.46  0.46  0.47  0.47\n",
      "   0.48  0.48  0.5   0.51]\n",
      " [ 0.36  0.38  0.39  0.4   0.4   0.4   0.41  0.41  0.41  0.41  0.42  0.42\n",
      "   0.42  0.42  0.42  0.42  0.43  0.43  0.43  0.43  0.43  0.43  0.43  0.43\n",
      "   0.43  0.44  0.44  0.44  0.44  0.44  0.44  0.44  0.44  0.45  0.45  0.45\n",
      "   0.45  0.45  0.45  0.45  0.45  0.45  0.46  0.46  0.46  0.46  0.46  0.46\n",
      "   0.46  0.46  0.46  0.47  0.47  0.47  0.47  0.47  0.47  0.47  0.47  0.47\n",
      "   0.48  0.48  0.48  0.48  0.48  0.48  0.48  0.48  0.48  0.48  0.48  0.49\n",
      "   0.49  0.49  0.49  0.49  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.51\n",
      "   0.51  0.51  0.51  0.52  0.52  0.53  0.53  0.53  0.53  0.53  0.53  0.54\n",
      "   0.54  0.56  0.58  0.6 ]]\n"
     ]
    }
   ],
   "source": [
    "sample_indices = np.load('Data/vis_indices.npy')\n",
    "X_test_samp = X_test[sample_indices]\n",
    "y_test_samp = np.array(y_test[sample_indices], dtype=int)\n",
    "midpt = np.load('Data/vis_midpt.npy')\n",
    "avg_length = np.load('Data/vis_avg_length.npy')\n",
    "min_scr, max_scr, pred = process(X_train, X_test_samp, y_train, y_test_samp)\n",
    "length = max_scr - min_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_v1",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert sum(min_scr <= midpt) >= (0.7 * len(sample_indices)), \"Incorrect range (mean - 3*std) to (mean + 3*std)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_v2",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert sum(max_scr >= midpt) >= (0.7 * len(sample_indices)), \"Incorrect range (mean - 3*std) to (mean + 3*std)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_v3",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert sum(length < 2*avg_length) >= (0.7 * len(sample_indices)), \"Incorrect length of range (mean - 3*std) to (mean + 3*std)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-43b23926ea9db62f",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test Here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-620ea86d73b4e234",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_h1",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_h2",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_h3",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_h4",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8ef0ac48c90e9575",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_h5",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_h6",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_h7",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "process_h8",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": [],
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": [],
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
